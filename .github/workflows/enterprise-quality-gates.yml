name: 🏢 Enterprise Quality Gates

on:
  push:
    branches: [main, develop, release/*]
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]
  schedule:
    # Run comprehensive quality checks daily
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      quality_level:
        description: 'Quality assurance level'
        type: choice
        options:
          - basic
          - standard
          - enterprise
          - regulatory-compliance
        default: 'enterprise'
      include_compliance:
        description: 'Include compliance checks'
        type: boolean
        default: true
      generate_reports:
        description: 'Generate detailed quality reports'
        type: boolean
        default: true

env:
  PYTHON_VERSION: '3.12.9'
  NODE_VERSION: '18'
  JAVA_VERSION: '11'

concurrency:
  group: quality-gates-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Code Quality Assessment
  code-quality-assessment:
    name: 📊 Code Quality Assessment
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      checks: write
      pull-requests: write

    outputs:
      quality-score: ${{ steps.assessment.outputs.score }}
      quality-grade: ${{ steps.assessment.outputs.grade }}
      meets-standards: ${{ steps.assessment.outputs.meets_standards }}

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install Quality Tools
        run: |
          python -m pip install --upgrade pip
          pip install pylint flake8 mypy black isort
          pip install pytest pytest-cov pytest-benchmark
          pip install radon xenon mccabe
          pip install bandit safety semgrep
          find . -name "requirements*.txt" -exec pip install -r {} \;

      - name: 🎨 Code Style Assessment
        run: |
          echo "🎨 Assessing code style..."

          # Format checking
          black --check --diff services/ shared/libraries/python/ sdk/python/ || echo "FORMAT_ISSUES=true" >> $GITHUB_ENV
          isort --check-only --diff services/ shared/libraries/python/ sdk/python/ || echo "IMPORT_ISSUES=true" >> $GITHUB_ENV

          # Linting
          flake8 services/ shared/libraries/python/ sdk/python/ --output-file=flake8-report.txt --tee
          pylint services/ shared/libraries/python/ sdk/python/ --output-format=json > pylint-report.json || true

      - name: 🔍 Code Complexity Analysis
        run: |
          echo "🔍 Analyzing code complexity..."

          # Cyclomatic complexity
          radon cc services/ --json > complexity-report.json
          radon mi services/ --json > maintainability-report.json

          # Halstead complexity
          radon hal services/ --json > halstead-report.json

          # Code duplication (using custom script)
          python tools/quality/duplicate_detector.py services/ > duplication-report.json

      - name: 🧪 Test Coverage Assessment
        run: |
          echo "🧪 Assessing test coverage..."

          # Run tests with coverage
          python -m pytest tests/ --cov=services/ --cov=shared/libraries/python/ \
            --cov-report=xml --cov-report=html --cov-report=json \
            --junitxml=junit-report.xml

      - name: 🛡️ Security Quality Gates
        run: |
          echo "🛡️ Running security quality gates..."

          # Static security analysis
          bandit -r services/ -f json -o bandit-report.json || true
          safety check --json > safety-report.json || true

          # Semgrep security scan
          semgrep --config=auto --json --output=semgrep-report.json services/ || true

      - name: 📊 Quality Score Calculation
        id: assessment
        run: |
          echo "📊 Calculating overall quality score..."

          python tools/quality/quality_calculator.py \
            --pylint-report pylint-report.json \
            --complexity-report complexity-report.json \
            --coverage-report coverage.json \
            --security-report bandit-report.json \
            --duplication-report duplication-report.json \
            --output quality-assessment.json

          # Extract scores
          SCORE=$(jq -r '.overall_score' quality-assessment.json)
          GRADE=$(jq -r '.grade' quality-assessment.json)
          MEETS_STANDARDS=$(jq -r '.meets_enterprise_standards' quality-assessment.json)

          echo "score=$SCORE" >> $GITHUB_OUTPUT
          echo "grade=$GRADE" >> $GITHUB_OUTPUT
          echo "meets_standards=$MEETS_STANDARDS" >> $GITHUB_OUTPUT

          echo "📊 Quality Score: $SCORE"
          echo "📊 Quality Grade: $GRADE"
          echo "📊 Meets Standards: $MEETS_STANDARDS"

      - name: 📊 Upload Quality Reports
        uses: actions/upload-artifact@v3
        with:
          name: quality-reports
          path: |
            *-report.json
            *-report.txt
            *-report.xml
            htmlcov/

  # Security Compliance Gates
  security-compliance:
    name: 🛡️ Security Compliance Gates
    runs-on: ubuntu-latest
    if: github.event.inputs.include_compliance == 'true' || github.event.inputs.include_compliance == ''

    permissions:
      security-events: write
      contents: read

    outputs:
      security-score: ${{ steps.security.outputs.score }}
      compliance-status: ${{ steps.compliance.outputs.status }}

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🔍 Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: python, javascript, java
          queries: security-extended,security-and-quality

      - name: 🏗️ CodeQL Analysis
        uses: github/codeql-action/analyze@v3

      - name: 🛡️ Comprehensive Security Scan
        id: security
        run: |
          echo "🛡️ Running comprehensive security scan..."

          # Install security tools
          pip install safety pip-audit semgrep

          # Dependency vulnerability scan
          pip-audit --format=json --output=dependency-vulnerabilities.json || true
          safety check --json > safety-vulnerabilities.json || true

          # Code security scan
          semgrep --config=p/security-audit --config=p/secrets --json services/ > semgrep-security.json || true

          # Calculate security score
          python tools/security/security_calculator.py \
            --dependency-report dependency-vulnerabilities.json \
            --safety-report safety-vulnerabilities.json \
            --semgrep-report semgrep-security.json \
            --output security-assessment.json

          SECURITY_SCORE=$(jq -r '.security_score' security-assessment.json)
          echo "score=$SECURITY_SCORE" >> $GITHUB_OUTPUT

      - name: 📋 Compliance Assessment
        id: compliance
        run: |
          echo "📋 Running compliance assessment..."

          # GDPR compliance check
          python tools/compliance/gdpr_checker.py services/ > gdpr-compliance.json

          # SOC2 compliance check
          python tools/compliance/soc2_checker.py services/ > soc2-compliance.json

          # HIPAA compliance check (if applicable)
          python tools/compliance/hipaa_checker.py services/ > hipaa-compliance.json

          # PCI DSS compliance check (if applicable)
          python tools/compliance/pci_checker.py services/ > pci-compliance.json

          # Overall compliance status
          python tools/compliance/compliance_aggregator.py \
            --gdpr gdpr-compliance.json \
            --soc2 soc2-compliance.json \
            --hipaa hipaa-compliance.json \
            --pci pci-compliance.json \
            --output compliance-assessment.json

          COMPLIANCE_STATUS=$(jq -r '.overall_status' compliance-assessment.json)
          echo "status=$COMPLIANCE_STATUS" >> $GITHUB_OUTPUT

  # Performance Quality Gates
  performance-gates:
    name: ⚡ Performance Quality Gates
    runs-on: ubuntu-latest

    outputs:
      performance-score: ${{ steps.performance.outputs.score }}
      meets-sla: ${{ steps.sla.outputs.meets_sla }}

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4

      - name: 🐳 Setup Test Environment
        run: |
          docker-compose -f docker-compose.yml up -d
          sleep 30

      - name: ⚡ Performance Benchmarks
        id: performance
        run: |
          echo "⚡ Running performance benchmarks..."

          pip install locust pytest-benchmark requests

          # API performance tests
          python -m pytest tests/benchmarks/ --benchmark-json=benchmark-results.json

          # Load test with minimal load
          locust --headless --users 50 --spawn-rate 5 --run-time 2m \
                 --host http://localhost:8000 \
                 --html performance-report.html \
                 --csv performance-results \
                 -f tests/performance/quick_load_test.py

          # Calculate performance score
          python tools/performance/performance_calculator.py \
            --benchmark-results benchmark-results.json \
            --load-results performance-results_stats.csv \
            --output performance-assessment.json

          PERF_SCORE=$(jq -r '.performance_score' performance-assessment.json)
          echo "score=$PERF_SCORE" >> $GITHUB_OUTPUT

      - name: 📊 SLA Validation
        id: sla
        run: |
          echo "📊 Validating SLA requirements..."

          # Check SLA requirements
          python tools/performance/sla_validator.py \
            --performance-data performance-assessment.json \
            --sla-config config/sla-requirements.yaml \
            --output sla-validation.json

          MEETS_SLA=$(jq -r '.meets_sla' sla-validation.json)
          echo "meets_sla=$MEETS_SLA" >> $GITHUB_OUTPUT

  # Enterprise Gate Decision
  enterprise-gate-decision:
    name: 🏢 Enterprise Gate Decision
    runs-on: ubuntu-latest
    needs: [code-quality-assessment, security-compliance, performance-gates]

    outputs:
      gate-status: ${{ steps.decision.outputs.status }}
      overall-score: ${{ steps.decision.outputs.overall_score }}

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4

      - name: 🏢 Enterprise Gate Evaluation
        id: decision
        run: |
          echo "🏢 Evaluating enterprise quality gates..."

          # Collect all scores
          QUALITY_SCORE="${{ needs.code-quality-assessment.outputs.quality-score }}"
          SECURITY_SCORE="${{ needs.security-compliance.outputs.security-score }}"
          PERFORMANCE_SCORE="${{ needs.performance-gates.outputs.performance-score }}"

          MEETS_STANDARDS="${{ needs.code-quality-assessment.outputs.meets-standards }}"
          COMPLIANCE_STATUS="${{ needs.security-compliance.outputs.compliance-status }}"
          MEETS_SLA="${{ needs.performance-gates.outputs.meets-sla }}"

          # Calculate overall score and gate status
          python tools/quality/enterprise_gate.py \
            --quality-score "$QUALITY_SCORE" \
            --security-score "$SECURITY_SCORE" \
            --performance-score "$PERFORMANCE_SCORE" \
            --meets-standards "$MEETS_STANDARDS" \
            --compliance-status "$COMPLIANCE_STATUS" \
            --meets-sla "$MEETS_SLA" \
            --quality-level "${{ github.event.inputs.quality_level || 'enterprise' }}" \
            --output enterprise-gate-result.json

          GATE_STATUS=$(jq -r '.gate_status' enterprise-gate-result.json)
          OVERALL_SCORE=$(jq -r '.overall_score' enterprise-gate-result.json)

          echo "status=$GATE_STATUS" >> $GITHUB_OUTPUT
          echo "overall_score=$OVERALL_SCORE" >> $GITHUB_OUTPUT

          if [[ "$GATE_STATUS" == "PASSED" ]]; then
            echo "✅ Enterprise quality gates PASSED"
          else
            echo "❌ Enterprise quality gates FAILED"
            exit 1
          fi

  # Quality Report Generation
  generate-quality-report:
    name: 📊 Generate Quality Report
    runs-on: ubuntu-latest
    needs:
      [code-quality-assessment, security-compliance, performance-gates, enterprise-gate-decision]
    if: always() && (github.event.inputs.generate_reports == 'true' || github.event.inputs.generate_reports == '')

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4

      - name: 📥 Download All Reports
        uses: actions/download-artifact@v3

      - name: 📊 Generate Comprehensive Report
        run: |
          echo "📊 Generating comprehensive quality report..."

          pip install jinja2 matplotlib plotly pandas

          python tools/reports/quality_report_generator.py \
            --quality-reports quality-reports/ \
            --gate-status "${{ needs.enterprise-gate-decision.outputs.gate-status }}" \
            --overall-score "${{ needs.enterprise-gate-decision.outputs.overall-score }}" \
            --output enterprise-quality-report.html

      - name: 📊 Upload Quality Report
        uses: actions/upload-artifact@v3
        with:
          name: enterprise-quality-report
          path: enterprise-quality-report.html

      - name: 💬 Comment Quality Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const gateStatus = '${{ needs.enterprise-gate-decision.outputs.gate-status }}';
            const overallScore = '${{ needs.enterprise-gate-decision.outputs.overall-score }}';
            const statusIcon = gateStatus === 'PASSED' ? '✅' : '❌';

            const message = `## 🏢 Enterprise Quality Gates ${statusIcon}\n\n` +
              `**Overall Status:** ${gateStatus}\n` +
              `**Overall Score:** ${overallScore}/100\n\n` +
              `**Gate Results:**\n` +
              `- Code Quality: ${{ needs.code-quality-assessment.outputs.quality-grade }} (${{ needs.code-quality-assessment.outputs.quality-score }}/100)\n` +
              `- Security Score: ${{ needs.security-compliance.outputs.security-score }}/100\n` +
              `- Performance Score: ${{ needs.performance-gates.outputs.performance-score }}/100\n` +
              `- Compliance: ${{ needs.security-compliance.outputs.compliance-status }}\n` +
              `- Meets Standards: ${{ needs.code-quality-assessment.outputs.meets-standards }}\n` +
              `- Meets SLA: ${{ needs.performance-gates.outputs.meets-sla }}\n\n` +
              `📊 Detailed reports available in workflow artifacts.`;
              
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: message
            });
