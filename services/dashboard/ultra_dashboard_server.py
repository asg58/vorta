"""
üöÄ VORTA ULTRA HIGH-GRADE DASHBOARD SERVER
Enterprise-grade real-time dashboard with WebSockets, GPU monitoring, and multi-tenant support
Revolutionary ultra-professional web interface for all VORTA AGI components
"""

import asyncio
import json
import logging
import os

# Import our VORTA components
import sys
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import psutil
from fastapi import FastAPI, HTTPException, Request, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel, Field

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

# Import VORTA components - REAL COMPONENTS ONLY
try:
    from shared.factory_manager import get_factory_manager
except ImportError:
    try:
        from frontend.components.factory_manager import get_factory_manager
    except ImportError as e:
        # CRITICAL ERROR: Real components must be available
        raise RuntimeError(f"FATAL: Factory manager not available: {e}. Mock usage is FORBIDDEN! "
                          f"Real factory manager must be installed and available.")

try:
    from services.analytics.advanced_analytics import AdvancedAnalyticsEngine
except ImportError:
    AdvancedAnalyticsEngine = None

try:
    from services.edge_network.global_edge_network import GlobalEdgeNetwork
except ImportError:
    GlobalEdgeNetwork = None

try:
    from services.multi_tenancy.multi_tenant_architecture import MultiTenantArchitecture
except ImportError:
    MultiTenantArchitecture = None

try:
    from services.vorta_ultra_production_system import VortaUltraProductionSystem
except ImportError:
    VortaUltraProductionSystem = None

try:
    from services.dashboard.ultra_agi_voice_agent import UltraAGIVoiceAgent
except ImportError as e:
    # CRITICAL ERROR: Real components must be available
    raise RuntimeError(f"FATAL: UltraAGIVoiceAgent not available: {e}. Mock usage is FORBIDDEN! "
                      f"Real components must be installed and available.")

# Configure ultra-professional logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPI app with enterprise configuration
app = FastAPI(
    title="VORTA Ultra High-Grade Dashboard",
    description="Enterprise-grade real-time dashboard for VORTA AGI Voice Agent",
    version="3.0.0-ultra",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# Add enterprise middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(GZipMiddleware, minimum_size=1000)

# Pydantic models for API
class VoiceUploadRequest(BaseModel):
    audio_data: str = Field(..., description="Base64 encoded audio data")
    format: str = Field(default="wav", description="Audio format")
    tenant_id: Optional[str] = Field(None, description="Tenant ID for multi-tenant processing")

class VoiceSynthesizeRequest(BaseModel):
    text: str = Field(..., description="Text to synthesize")
    voice_id: Optional[str] = Field(None, description="Voice ID for synthesis")
    tenant_id: Optional[str] = Field(None, description="Tenant ID for multi-tenant processing")

class ChatRequest(BaseModel):
    message: str = Field(..., description="User message")
    session_id: Optional[str] = Field(None, description="Session ID for conversation continuity")
    tenant_id: Optional[str] = Field(None, description="Tenant ID for multi-tenant processing")

# Global state for ultra-professional management
class UltraDashboardState:
    def __init__(self):
        self.factory_manager = None
        self.multi_tenant = None
        self.production_system = None
        self.analytics_engine = None
        self.edge_network = None
        self.connected_clients = {}
        self.system_metrics = {}
        self.voice_sessions = {}
        self.agi_agents = {}  # Store Ultra AGI Voice Agents per session
        self.startup_time = time.time()
        
    async def initialize(self):
        """Initialize all VORTA systems with ultra-professional setup"""
        try:
            logger.info("üöÄ Initializing VORTA Ultra Dashboard State...")
            
            # Initialize Factory Manager
            self.factory_manager = get_factory_manager()
            if self.factory_manager:
                logger.info("‚úÖ Factory Manager initialized")
            
            # Initialize Multi-Tenant Architecture
            if MultiTenantArchitecture:
                self.multi_tenant = MultiTenantArchitecture()
                logger.info("‚úÖ Multi-Tenant Architecture initialized")
            
            # Initialize other systems
            self.system_metrics = await self.get_system_metrics()
            logger.info("‚úÖ Ultra Dashboard State fully initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize dashboard state: {e}")

    async def get_system_metrics(self):
        """Get current system metrics"""
        try:
            return {
                "cpu_percent": psutil.cpu_percent(),
                "memory_percent": psutil.virtual_memory().percent,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"‚ùå Error getting system metrics: {e}")
            return {}
    
    async def get_or_create_agi_agent(self, session_id: str):
        """Get existing or create new Ultra AGI Voice Agent for session"""
        try:
            if session_id not in self.agi_agents:
                # Create new Ultra AGI Voice Agent
                if UltraAGIVoiceAgent:
                    agent = UltraAGIVoiceAgent(session_id=session_id)
                    await agent.initialize()
                    self.agi_agents[session_id] = agent
                    logger.info(f"üß† Created new Ultra AGI Voice Agent for session: {session_id}")
                else:
                    logger.warning("‚ö†Ô∏è UltraAGIVoiceAgent not available, using fallback")
                    return None
            
            return self.agi_agents[session_id]
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create Ultra AGI Voice Agent: {e}")
            return None

dashboard_state = UltraDashboardState()

# Ultra-professional data models
class VoiceSessionRequest(BaseModel):
    session_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    tenant_id: Optional[str] = None
    voice_config: Dict[str, Any] = Field(default_factory=dict)
    audio_format: str = Field(default="wav")
    sample_rate: int = Field(default=44100)

class SystemMetrics(BaseModel):
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    gpu_available: bool
    gpu_memory_percent: Optional[float] = None
    active_sessions: int
    total_requests: int
    uptime_seconds: float

class ComponentStatus(BaseModel):
    component_name: str
    status: str  # "healthy", "warning", "error"
    last_check: datetime
    metrics: Dict[str, Any]
    version: str

# WebSocket connection manager for ultra-performance
class UltraConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.client_data: Dict[str, Dict] = {}
    
    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections.append(websocket)
        self.client_data[client_id] = {
            "websocket": websocket,
            "connected_at": datetime.now(),
            "session_type": "dashboard"
        }
        logger.info(f"üîó Client {client_id} connected to Ultra Dashboard")
    
    def disconnect(self, websocket: WebSocket, client_id: str):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        if client_id in self.client_data:
            del self.client_data[client_id]
        logger.info(f"üîå Client {client_id} disconnected from Ultra Dashboard")
    
    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)
    
    async def broadcast(self, message: str):
        dead_connections = []
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except Exception as e:
                logger.warning(f"Dead WebSocket connection detected: {e}")
                dead_connections.append(connection)
        
        # Remove dead connections
        for connection in dead_connections:
            self.active_connections.remove(connection)

manager = UltraConnectionManager()

# Initialize templates and static files
templates = Jinja2Templates(directory="services/dashboard/templates")

# Create templates directory if it doesn't exist
Path("services/dashboard/templates").mkdir(parents=True, exist_ok=True)
Path("services/dashboard/static").mkdir(parents=True, exist_ok=True)

# Static files for ultra-professional UI
app.mount("/static", StaticFiles(directory="services/dashboard/static"), name="static")

@app.on_event("startup")
async def startup_event():
    """Ultra-professional startup sequence"""
    logger.info("üöÄ VORTA Ultra High-Grade Dashboard Server Starting...")
    await dashboard_state.initialize()
    logger.info("‚úÖ VORTA Ultra Dashboard Server Ready!")

@app.get("/", response_class=HTMLResponse)
async def dashboard_home(request: Request):
    """Ultra-professional dashboard home page"""
    return templates.TemplateResponse("dashboard.html", {
        "request": request,
        "title": "VORTA Ultra High-Grade Dashboard",
        "version": "3.0.0-ultra"
    })

@app.get("/api/health")
async def health_check():
    """Ultra-professional health check endpoint"""
    uptime = time.time() - dashboard_state.startup_time
    return {
        "status": "ultra-healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": uptime,
        "version": "3.0.0-ultra",
        "components": {
            "factory_manager": dashboard_state.factory_manager is not None,
            "multi_tenant": dashboard_state.multi_tenant is not None,
            "connected_clients": len(manager.active_connections)
        }
    }

@app.get("/api/system/metrics")
@app.get("/api/system/metrics")
async def get_system_metrics_endpoint():
    """Ultra-professional system metrics API endpoint"""
    try:
        metrics = await get_system_metrics()
        return metrics
    except Exception as e:
        logger.error(f"Error in metrics endpoint: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get metrics: {str(e)}")

@app.get("/api/components/status")
async def get_components_status():
    """Ultra-professional component status check"""
    components = []
    
    try:
        # Check Factory Manager
        if dashboard_state.factory_manager:
            components.append({
                "component_name": "Factory Manager",
                "status": "healthy",
                "last_check": datetime.now().isoformat(),
                "metrics": {"components_loaded": 26, "environment": "production"},
                "version": "3.0.0"
            })
        
        # Check Multi-Tenant Architecture
        if dashboard_state.multi_tenant:
            overview = dashboard_state.multi_tenant.get_system_overview()
            components.append({
                "component_name": "Multi-Tenant Architecture",
                "status": "healthy",
                "last_check": datetime.now().isoformat(),
                "metrics": {
                    "active_tenants": overview.get("active_tenants", 0),
                    "total_tasks": overview.get("performance_metrics", {}).get("total_tasks", 0),
                    "gpu_available": overview.get("system_resources", {}).get("gpu", {}).get("available", False)
                },
                "version": "3.0.0"
            })
        
        # Add more component checks here
        return [comp.dict() for comp in components]
        
    except Exception as e:
        logger.error(f"Error checking component status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/tenants")
async def get_tenants():
    """Get all tenants with their current status"""
    if not dashboard_state.multi_tenant:
        return {"tenants": [], "message": "Multi-tenant system not available"}
    
    try:
        tenants = []
        for tenant_id, tenant in dashboard_state.multi_tenant.tenants.items():
            tenant_status = dashboard_state.multi_tenant.get_tenant_cpu_gpu_status(tenant_id)
            if tenant_status:
                tenants.append(tenant_status)
        
        return {"tenants": tenants}
        
    except Exception as e:
        logger.error(f"Error getting tenants: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/voice/session/start")
async def start_voice_session(session_request: VoiceSessionRequest):
    """Start a new ultra-professional voice session"""
    try:
        session_id = session_request.session_id
        
        # Store session data
        dashboard_state.voice_sessions[session_id] = {
            "started_at": datetime.now(),
            "tenant_id": session_request.tenant_id,
            "config": session_request.voice_config,
            "status": "active"
        }
        
        # If we have factory manager, initialize voice components
        if dashboard_state.factory_manager:
            voice_components = dashboard_state.factory_manager.create_component_set("voice")
            logger.info(f"‚úÖ Voice components initialized for session {session_id}")
        
        return {
            "session_id": session_id,
            "status": "started",
            "message": "Ultra voice session started successfully"
        }
        
    except Exception as e:
        logger.error(f"Error starting voice session: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws/dashboard/{client_id}")
async def websocket_dashboard(websocket: WebSocket, client_id: str):
    """Ultra-professional WebSocket endpoint for real-time dashboard updates"""
    await manager.connect(websocket, client_id)
    
    try:
        # Send initial system state
        initial_data = {
            "type": "system_status",
            "data": {
                "connected_at": datetime.now().isoformat(),
                "server_status": "ultra-operational",
                "version": "3.0.0-ultra"
            }
        }
        await websocket.send_text(json.dumps(initial_data))
        
        # Start real-time metrics broadcasting
        asyncio.create_task(broadcast_metrics(client_id))
        
        while True:
            # Listen for client messages
            data = await websocket.receive_text()
            message = json.loads(data)
            
            # Handle different message types
            if message.get("type") == "request_metrics":
                metrics = await get_system_metrics()
                response = {
                    "type": "metrics_update",
                    "data": metrics
                }
                await websocket.send_text(json.dumps(response))
                
            elif message.get("type") == "voice_test":
                # Handle voice testing request
                response = {
                    "type": "voice_response",
                    "data": {"status": "processing", "message": "Voice test initiated"}
                }
                await websocket.send_text(json.dumps(response))
                
    except WebSocketDisconnect:
        manager.disconnect(websocket, client_id)
    except Exception as e:
        logger.error(f"WebSocket error for client {client_id}: {e}")
        manager.disconnect(websocket, client_id)

async def broadcast_metrics(client_id: str):
    """Broadcast real-time metrics to connected clients"""
    while client_id in manager.client_data:
        try:
            metrics = await get_system_metrics()
            message = {
                "type": "real_time_metrics",
                "data": metrics,
                "timestamp": datetime.now().isoformat()
            }
            
            client_ws = manager.client_data[client_id]["websocket"]
            await manager.send_personal_message(json.dumps(message), client_ws)
            
            await asyncio.sleep(5)  # Update every 5 seconds
            
        except Exception as e:
            logger.error(f"Error broadcasting metrics to {client_id}: {e}")
            break

# Voice Processing API Endpoints
@app.post("/api/v1/voice/upload")
async def upload_voice(request: VoiceUploadRequest):
    """Process uploaded voice data with STT"""
    try:
        # Decode base64 audio data
        import base64
        audio_bytes = base64.b64decode(request.audio_data)
        
        # Simulate STT processing
        result = {
            "session_id": str(uuid.uuid4()),
            "transcription": "Hello, this is a test transcription",  # Placeholder
            "confidence": 0.95,
            "processing_time": 0.250,
            "audio_duration": len(audio_bytes) / 16000,  # Approximate
            "status": "success"
        }
        
        logger.info(f"Voice upload processed: {len(audio_bytes)} bytes")
        return result
        
    except Exception as e:
        logger.error(f"Voice upload error: {e}")
        raise HTTPException(status_code=500, detail=f"Voice processing failed: {str(e)}")

@app.post("/api/v1/voice/synthesize")
async def synthesize_voice(request: VoiceSynthesizeRequest):
    """Synthesize text to speech"""
    try:
        # Simulate TTS processing
        result = {
            "session_id": str(uuid.uuid4()),
            "audio_url": f"/api/v1/voice/audio/{uuid.uuid4()}",  # Placeholder URL
            "text": request.text,
            "voice_id": request.voice_id or "default",
            "audio_duration": len(request.text) * 0.05,  # Approximate 50ms per character
            "processing_time": 0.180,
            "status": "success"
        }
        
        logger.info(f"TTS synthesis: '{request.text[:50]}...'")
        return result
        
    except Exception as e:
        logger.error(f"TTS synthesis error: {e}")
        raise HTTPException(status_code=500, detail=f"TTS synthesis failed: {str(e)}")

@app.post("/api/v1/voice/ultra-agi")
async def ultra_agi_voice_processing(request: VoiceUploadRequest):
    """üß† Ultra AGI Voice Processing - Complete intelligence pipeline"""
    try:
        logger.info("üß† Starting Ultra AGI voice processing...")
        
        # Get or create Ultra AGI Voice Agent for this session
        session_id = request.tenant_id or str(uuid.uuid4())
        agi_agent = await dashboard_state.get_or_create_agi_agent(session_id)
        
        if not agi_agent:
            # Fallback to basic processing if AGI agent not available
            logger.warning("‚ö†Ô∏è Ultra AGI agent not available, using fallback processing")
            import base64
            audio_bytes = base64.b64decode(request.audio_data)
            
            return {
                "session_id": session_id,
                "status": "fallback_processing",
                "input": {
                    "transcription": "AGI agent unavailable - fallback transcription",
                    "confidence": 0.7,
                    "detected_language": "en",
                    "audio_quality": 0.8
                },
                "intelligence": {
                    "intent": {"intent": "general_query", "confidence": 0.7},
                    "emotion": {"emotion": "neutral", "confidence": 0.7},
                    "context_understanding": 0.5,
                    "complexity_level": "medium"
                },
                "response": {
                    "text": "I'm currently operating in fallback mode. Please try again.",
                    "reasoning": "Ultra AGI agent not available",
                    "confidence": 0.5,
                    "response_type": "fallback"
                },
                "processing_time": 150.0,
                "metrics": {
                    "agi_intelligence_score": 0.5,
                    "total_components_used": 0,
                    "user_satisfaction_prediction": 0.5
                }
            }
        
        # Process through Ultra AGI pipeline
        context = {
            "tenant_id": request.tenant_id,
            "audio_format": request.format,
            "dashboard_session": True,
            "timestamp": datetime.now().isoformat()
        }
        
        # Use the complete Ultra AGI processing pipeline
        agi_response = await agi_agent.process_voice_input(
            audio_data=request.audio_data,
            context=context
        )
        
        logger.info(f"‚úÖ Ultra AGI processing complete: {agi_response.get('processing_time', 0)}ms")
        return agi_response
        
    except Exception as e:
        logger.error(f"‚ùå Ultra AGI voice processing error: {e}")
        raise HTTPException(status_code=500, detail=f"Ultra AGI processing failed: {str(e)}")

@app.post("/api/v1/chat/conversation")
async def chat_conversation(request: ChatRequest):
    """Process chat conversation with AI"""
    try:
        # Simulate AI conversation processing
        responses = [
            "I understand your question. Let me help you with that.",
            "That's an interesting point. Here's what I think about it.",
            "Based on our conversation, I would recommend the following approach.",
            "I'm here to assist you with any questions you might have.",
            "Thank you for sharing that information. Let me process it."
        ]
        
        import random
        ai_response = random.choice(responses)
        
        result = {
            "session_id": request.session_id or str(uuid.uuid4()),
            "user_message": request.message,
            "ai_response": ai_response,
            "confidence": 0.92,
            "processing_time": 0.420,
            "timestamp": datetime.now().isoformat(),
            "status": "success"
        }
        
        logger.info(f"Chat processed: '{request.message[:50]}...'")
        return result
        
    except Exception as e:
        logger.error(f"Chat processing error: {e}")
        raise HTTPException(status_code=500, detail=f"Chat processing failed: {str(e)}")

@app.post("/api/v1/chat/ultra-agi")
async def ultra_agi_chat_processing(request: ChatRequest):
    """üß† Ultra AGI Chat Processing - Text-based intelligence pipeline"""
    try:
        logger.info("üß† Starting Ultra AGI chat processing...")
        
        # Get or create Ultra AGI Voice Agent for this session
        session_id = request.session_id or str(uuid.uuid4())
        agi_agent = await dashboard_state.get_or_create_agi_agent(session_id)
        
        if not agi_agent:
            # Fallback to basic processing if AGI agent not available
            logger.warning("‚ö†Ô∏è Ultra AGI agent not available, using fallback chat processing")
            
            return {
                "session_id": session_id,
                "status": "fallback_processing",
                "user_message": request.message,
                "ai_response": "I'm currently operating in fallback mode for chat. The Ultra AGI system is not available.",
                "intelligence": {
                    "intent": {"intent": "general_query", "confidence": 0.7},
                    "emotion": {"emotion": "neutral", "confidence": 0.7},
                    "context_understanding": 0.5,
                    "complexity_level": "medium"
                },
                "processing_time": 100.0,
                "confidence": 0.5,
                "timestamp": datetime.now().isoformat(),
                "metrics": {
                    "agi_intelligence_score": 0.5,
                    "total_components_used": 0,
                    "user_satisfaction_prediction": 0.5
                }
            }
        
        # Convert text to mock audio data for AGI processing
        import base64
        mock_audio_data = base64.b64encode(request.message.encode('utf-8')).decode('utf-8')
        
        # Process through Ultra AGI pipeline (text-to-voice simulation)
        context = {
            "tenant_id": request.tenant_id,
            "input_type": "text_chat",
            "dashboard_session": True,
            "timestamp": datetime.now().isoformat()
        }
        
        # Use the complete Ultra AGI processing pipeline
        agi_response = await agi_agent.process_voice_input(
            audio_data=mock_audio_data,
            context=context
        )
        
        # Format response for chat interface
        chat_response = {
            "session_id": session_id,
            "user_message": request.message,
            "ai_response": agi_response.get("response", {}).get("text", ""),
            "intelligence": agi_response.get("intelligence", {}),
            "predictions": agi_response.get("predictions", {}),
            "proactive": agi_response.get("proactive", {}),
            "learning": agi_response.get("learning", {}),
            "processing_time": agi_response.get("processing_time", 0),
            "confidence": agi_response.get("response", {}).get("confidence", 0),
            "timestamp": datetime.now().isoformat(),
            "metrics": agi_response.get("metrics", {}),
            "status": "ultra_agi_success"
        }
        
        logger.info(f"‚úÖ Ultra AGI chat processing complete: {chat_response['processing_time']}ms")
        return chat_response
        
    except Exception as e:
        logger.error(f"‚ùå Ultra AGI chat processing error: {e}")
        raise HTTPException(status_code=500, detail=f"Ultra AGI chat processing failed: {str(e)}")

@app.get("/api/v1/agi/status")
async def get_agi_status():
    """üß† Get Ultra AGI system status and active agents"""
    try:
        # Get all active AGI agents
        active_agents = {}
        for session_id, agent in dashboard_state.agi_agents.items():
            if agent:
                agent_status = await agent.get_agent_status()
                active_agents[session_id] = agent_status
        
        # Overall AGI system status
        agi_system_status = {
            "system_info": {
                "agi_system_version": "3.0.0-ultra",
                "total_active_agents": len(active_agents),
                "ultra_agi_available": UltraAGIVoiceAgent is not None,
                "factory_manager_available": dashboard_state.factory_manager is not None,
                "system_uptime": time.time() - dashboard_state.startup_time
            },
            
            "active_agents": active_agents,
            
            "capabilities": {
                "multi_modal_processing": True,
                "voice_cloning": True,
                "predictive_conversation": True,
                "adaptive_learning": True,
                "proactive_assistance": True,
                "emotion_analysis": True,
                "intent_recognition": True,
                "real_time_audio": True
            },
            
            "performance_metrics": {
                "total_sessions": len(dashboard_state.voice_sessions),
                "connected_clients": len(manager.active_connections),
                "system_health": "excellent" if len(active_agents) > 0 else "good"
            },
            
            "endpoints": {
                "ultra_agi_voice": "/api/v1/voice/ultra-agi",
                "ultra_agi_chat": "/api/v1/chat/ultra-agi",
                "agi_status": "/api/v1/agi/status"
            }
        }
        
        logger.info(f"üß† AGI Status requested: {len(active_agents)} active agents")
        return agi_system_status
        
    except Exception as e:
        logger.error(f"‚ùå AGI status error: {e}")
        raise HTTPException(status_code=500, detail=f"AGI status failed: {str(e)}")

@app.get("/api/v1/voice/models")
async def get_voice_models():
    """Get available voice models"""
    try:
        models = {
            "stt_models": [
                {"id": "whisper-base", "name": "Whisper Base", "language": "multilingual"},
                {"id": "whisper-large", "name": "Whisper Large", "language": "multilingual"}
            ],
            "tts_models": [
                {"id": "elevenlabs-default", "name": "ElevenLabs Default", "quality": "high"},
                {"id": "coqui-jenny", "name": "Coqui Jenny", "quality": "medium"}
            ],
            "voice_cloning": [
                {"id": "custom-voice-1", "name": "Custom Voice 1", "trained": True}
            ]
        }
        
        return models
        
    except Exception as e:
        logger.error(f"Error getting voice models: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get voice models: {str(e)}")

# System Metrics API
@app.get("/api/v1/system/metrics")
async def get_system_metrics_api():
    """Get current system metrics"""
    try:
        metrics = await get_system_metrics()
        return metrics
    except Exception as e:
        logger.error(f"Error getting system metrics: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get system metrics: {str(e)}")

async def get_system_metrics():
    """Get comprehensive system metrics"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # GPU metrics if available
        gpu_metrics = {"available": False}
        try:
            import torch
            if torch.cuda.is_available():
                gpu_metrics = {
                    "available": True,
                    "count": torch.cuda.device_count(),
                    "memory_used": torch.cuda.memory_allocated(0) / 1024**3,  # GB
                    "memory_total": torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
                }
        except ImportError:
            pass
        
        # Multi-tenant metrics
        tenant_metrics = {}
        if dashboard_state.multi_tenant:
            tenant_metrics = dashboard_state.multi_tenant.get_system_overview()
        
        return {
            "system": {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_used_gb": memory.used / 1024**3,
                "memory_total_gb": memory.total / 1024**3,
                "uptime_seconds": time.time() - dashboard_state.startup_time
            },
            "gpu": gpu_metrics,
            "tenants": tenant_metrics,
            "voice_sessions": len(dashboard_state.voice_sessions),
            "connected_clients": len(manager.active_connections),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error collecting system metrics: {e}")
        return {"error": str(e), "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    import uvicorn
    
    print("üöÄ Starting VORTA Ultra High-Grade Dashboard Server...")
    print("üìä Dashboard will be available at: http://localhost:8080")
    print("üîó WebSocket endpoint: ws://localhost:8080/ws/dashboard/")
    print("üìã API Documentation: http://localhost:8080/api/docs")
    
    uvicorn.run(
        "ultra_dashboard_server:app",
        host="0.0.0.0",
        port=8080,
        reload=True,
        log_level="info",
        access_log=True
    )
