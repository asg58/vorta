# VORTA Project - AI Assistant Context Configuration

# =============================================================================
# ðŸ§  PERMANENT MEMORY INJECTION FOR AI ASSISTANTS
# =============================================================================

[project]
name = "VORTA"
type = "Enterprise AI Platform"
status = "78% Complete - Production Ready"
architecture = "Microservices with AI/Voice Processing"
priority = "CRITICAL - Pilot Deployment Ready"

[critical_context]
# Essential information that must ALWAYS be remembered
context_memory_manager = "1400+ lines at frontend/components/ai/context_memory_manager.py - NEEDS 'import re' fix"
api_backend = "538 lines FastAPI at services/api/main.py - Production ready"
enterprise_dashboard = "450+ lines Streamlit at frontend/vorta_enterprise_dashboard.py - 95% complete"

[immediate_fixes]
# Critical issues that must be fixed FIRST
missing_import = "Add 'import re' to context_memory_manager.py line 28"
test_completion = "Complete test function with asyncio.run(test_context_memory())"
websocket_streaming = "Implement WebSocket endpoints for real-time voice"
load_testing = "Create framework for 100+ concurrent user testing"

[performance_targets]
memory_retrieval = "<50ms"
api_response = "<100ms" 
voice_processing = "<50ms"
gpu_utilization = "30-70%"
concurrent_users = ">100"
system_availability = ">99.9%"

[architecture_layers]
presentation = "Streamlit Dashboard + REST API + WebSocket"
application = "AI Processing + Voice Pipeline + Context Memory"
service = "API Gateway + Inference Engine + Vector Store"
data = "PostgreSQL + Redis + FAISS + MinIO"
infrastructure = "Docker + Kubernetes + Prometheus/Grafana"

[completion_status]
enterprise_architecture = "100%"
voice_processing = "100%"
ai_stack = "95%"
backend_infrastructure = "100%"
frontend_integration = "85%"
performance_testing = "20%"
customer_validation = "10%"

[development_commands]
setup = "make setup-dev"
start_services = "make start-dev"  
start_app = "make start-app"
test = "make test"
format = "make format"

[success_metrics]
code_quality = "9.2/10 average"
test_coverage = "70% (target: 90%)"
performance = "<100ms latency"
reliability = "100% success rate"
gpu_optimization = "37.5% utilization"

[ai_assistant_reminders]
# Critical reminders for AI assistants
always_remember = [
    "VORTA is 78% complete enterprise AI platform",
    "Context Memory Manager needs 'import re' fix",
    "WebSocket streaming is high priority", 
    "Performance target is <50ms for memory retrieval",
    "GPU optimization for RTX 4060 8GB is critical",
    "8 Docker services are operational",
    "Production deployment possible within 8-12 weeks"
]

[file_locations]
# Critical file paths to remember
context_manager = "frontend/components/ai/context_memory_manager.py"
api_main = "services/api/main.py" 
dashboard = "frontend/vorta_enterprise_dashboard.py"
analysis_report = "VORTA_CODEBASE_ANALYSIS_REPORT.md"
docker_compose = "docker-compose.yml"
